{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import talib as ta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor,VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "DataFrame = pd.DataFrame\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data:pd.DataFrame):\n",
    "    # 生成技术指标\n",
    "    data['SMA'] = data['close'].rolling(window=20).mean()\n",
    "    data['EMA20'] = data['close'].ewm(span=20, adjust=False).mean()\n",
    "    data['MACD'] = data['close'].ewm(span=12, adjust=False).mean() - data['close'].ewm(span=26, adjust=False).mean()\n",
    "    data['Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    data['MACD_Histogram'] = data['MACD'] - data['Signal']\n",
    "    data['RSI'] = ta.RSI(data['close'], timeperiod=14)\n",
    "    data['UpperBB'],data['MiddleBB'],data['LowerBB'] = ta.BBANDS(data['close'], timeperiod=20)\n",
    "    data['ATR'] = ta.ATR(data['high'], data['low'], data['close'], timeperiod=14)\n",
    "    data['Volatility'] = data['ATR'] / data['close']\n",
    "    return data.sort_values(by='date', ascending=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data:DataFrame, lookahead = 5):\n",
    "    # 特征工程\n",
    "    for lag in [1, 3, 5]:\n",
    "        data[f'return_lag{lag}'] = data['close'].pct_change(lag)\n",
    "    # 添加技术指标交叉信号\n",
    "    data['MACD_cross'] = np.where(data['MACD'] > data['Signal'], 1, -1)\n",
    "    data['BB_width'] = (data['UpperBB'] - data['LowerBB']) / data['MiddleBB']\n",
    "    # 未来收益率\n",
    "    data['future_return'] = data['close'].pct_change(lookahead).shift(-lookahead)\n",
    "\n",
    "    data['log_return'] = np.log(data['close']).diff()\n",
    "    data['volatility_30'] = data['log_return'].rolling(30).std()\n",
    "    # 新增时间序列特征\n",
    "    data['month'] = data.index.month\n",
    "    data['day_of_week'] = data.index.dayofweek\n",
    "\n",
    "    # 特征选择\n",
    "    selected_features = ['RSI', 'MACD','Signal', 'volatility_30',  'UpperBB', 'MiddleBB', 'LowerBB', 'BB_width',\n",
    "                        'return_lag1', 'return_lag3', 'month']\n",
    "    data['return'] = data['close'].pct_change()\n",
    "    # 确保时间对齐\n",
    "    data = data.dropna()\n",
    "    return  data[selected_features], data['future_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_configs() -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"统一管理模型配置\"\"\"\n",
    "    return {\n",
    "        'random_forest': {\n",
    "            'pipeline': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', RandomForestRegressor())\n",
    "            ]),\n",
    "            'param_grid': {\n",
    "                'regressor__n_estimators': [100, 200],\n",
    "                'regressor__max_depth': [5, 8]\n",
    "            }\n",
    "        },\n",
    "        'xgb': {\n",
    "            'pipeline': Pipeline([\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('regressor', XGBRegressor(\n",
    "                    objective='reg:squarederror', \n",
    "                    n_jobs=-1\n",
    "                ))\n",
    "            ]),\n",
    "            'param_grid': {\n",
    "                'regressor__learning_rate': [0.01, 0.1],\n",
    "                'regressor__max_depth': [3, 5],\n",
    "                'regressor__n_estimators': [100, 200]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(\n",
    "    model: BaseEstimator,\n",
    "    param_grid: Dict[str, Any],\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    tscv: TimeSeriesSplit\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"通用交叉验证流程\"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    return {\n",
    "        'best_model': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_results': grid_search.cv_results_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(model, feature_names):\n",
    "    \"\"\"可视化特征重要性\"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "    try:\n",
    "         # 兼容不同模型结构\n",
    "        if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "            importance = pd.Series(model.named_steps['regressor'].feature_importances_,index=feature_names).sort_values()\n",
    "\n",
    "        elif hasattr(model.named_steps['regressor'], 'coef_'):\n",
    "            importance = np.abs(model.named_steps['regressor'].coef_)\n",
    "        else:\n",
    "            raise AttributeError(\"模型不支持特征重要性分析\")\n",
    "                \n",
    "        importance.plot(kind='barh', title='Feature Importance')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"特征分析失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X, y):\n",
    "    \"\"\"多模型集成训练入口\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=5, test_size=21)\n",
    "    model_configs = get_model_configs()\n",
    "    results = {}\n",
    "    for model_name, config in model_configs.items():\n",
    "        model_result = cross_validate_model(\n",
    "            config['pipeline'],\n",
    "            config['param_grid'],\n",
    "            X, y, tscv\n",
    "        )\n",
    "        # 保存基准分数到模型对象\n",
    "        model_result['best_model'].baseline_score = model_result['cv_results']['mean_test_score'].max()\n",
    "        # 存储每个模型的最佳结果\n",
    "        results[model_name] = {\n",
    "            'model': model_result['best_model'],\n",
    "            'params': model_result['best_params'],\n",
    "            'cv_score': model_result['cv_results']['mean_test_score'].max()\n",
    "        }\n",
    "         # 新增特征分析\n",
    "        analyze_features(\n",
    "            model_result['best_model'],\n",
    "            feature_names=X.columns.tolist()\n",
    "        )\n",
    "        print(f\"{model_name.upper()} 最佳参数: {model_result['best_params']}\")\n",
    "        print(f\"平均验证得分: {model_result['cv_results']['mean_test_score'].max():.3f}\")\n",
    "    # 为集成模型创建基准分数（取各模型平均）\n",
    "    ensemble_baseline = np.mean([results[model]['cv_score'] for model in results])\n",
    "    ensemble = VotingRegressor(\n",
    "        [(name, results['model']) for name, results in results.items()]\n",
    "    )\n",
    "    ensemble.baseline_score = ensemble_baseline  # 添加基准分数属性\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_model_drift(model, X: pd.DataFrame, y: pd.Series, n_folds: int = 5) -> float:\n",
    "    \"\"\"监控模型性能漂移\n",
    "    Args:\n",
    "        model: 已训练的基准模型\n",
    "        X: 新数据特征\n",
    "        y: 新数据目标值\n",
    "        n_folds: 交叉验证折数\n",
    "    \n",
    "    Returns:\n",
    "        当前分数与基准分数的差值\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_score = cross_val_score(model, X, y, cv=5).mean()\n",
    "        baseline_score = model.baseline_score  # 从保存的基准模型中读取\n",
    "    except Exception as e:\n",
    "        logging.error(f\"漂移检测失败: {str(e)}\")\n",
    "        return np.nan\n",
    "    # 从已保存的基准模型读取历史分数\n",
    "    baseline_score = getattr(model, 'baseline_score', None)\n",
    "    if baseline_score is None:\n",
    "        baseline_score = current_score\n",
    "        logging.warning(\"未找到基准分数，使用当前分数作为基准\")\n",
    "    \n",
    "    return current_score - baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor:\n",
    "    \"\"\"模型监控管理器\"\"\"\n",
    "    def __init__(self, baseline_model_path):\n",
    "        self.baseline = joblib.load(baseline_model_path)\n",
    "        self.baseline_score = self.baseline.baseline_score\n",
    "        \n",
    "    def check_drift(self, X_new, y_new, threshold=0.1):\n",
    "        # 添加时间序列有效性验证\n",
    "        if not isinstance(X_new.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"输入数据需要包含有效时间索引\")\n",
    "            \n",
    "        # 添加数据时效性检查（最新数据不应早于3天前）\n",
    "        latest_date = X_new.index.max()\n",
    "        if pd.Timestamp.now() - latest_date > pd.Timedelta(days=3):\n",
    "            logging.warning(\"检测到过期数据：{latest_date}\")\n",
    "\n",
    "        current = cross_val_score(\n",
    "            self.baseline, X_new, y_new,\n",
    "            cv=TimeSeriesSplit(3),\n",
    "            scoring='neg_mean_squared_error'\n",
    "        ).mean()\n",
    "        return (current - self.baseline_score) < threshold\n",
    "    \n",
    "    def plot_performance(self, historical_data):\n",
    "        \"\"\"性能趋势可视化\"\"\"\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(historical_data['dates'], historical_data['scores'], \n",
    "                label='当前表现')\n",
    "        plt.axhline(self.baseline_score, color='r', \n",
    "                   linestyle='--', label='基准表现')\n",
    "        plt.title('Model Performance Monitoring')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting import Backtest, Strategy\n",
    "\n",
    "class ModelDrivenStrategy(Strategy):\n",
    "    \"\"\"基于模型预测的交易策略\"\"\"\n",
    "    # 策略参数\n",
    "    threshold_entry = 0.02  # 买入阈值\n",
    "    threshold_exit = -0.01  # 卖出阈值\n",
    "    position_size = 0.1  # 仓位比例\n",
    "    \n",
    "    def init(self):\n",
    "        # 加载预训练模型\n",
    "        self.model = joblib.load('stock_predictor.pkl')\n",
    "        \n",
    "        # 初始化指标计算窗口\n",
    "        self.returns = self.I(self.calculate_returns)\n",
    "        \n",
    "    def calculate_returns(self):\n",
    "        \"\"\"实时计算收益率特征\"\"\"\n",
    "        close = self.data.Close.df\n",
    "        return close.pct_change()\n",
    "    \n",
    "    def next(self):\n",
    "        # 仅在有足够历史数据时交易\n",
    "        if len(self.data) < 30:\n",
    "            return\n",
    "        \n",
    "        # 构建特征数据\n",
    "        current_idx = len(self.data) - 1\n",
    "        features = pd.DataFrame({\n",
    "            'RSI': self.data['RSI'][-20:].mean(),\n",
    "            'MACD': self.data['MACD'][-1],\n",
    "            'volatility': self.data['volatility_30'][-1],\n",
    "            'BB_width': self.data['BB_width'][-1],\n",
    "            'return_lag1': self.returns[-1],\n",
    "            'return_lag3': self.returns[-3:].mean(),\n",
    "            'month': self.data.df.index[-1].month\n",
    "        }, index=[current_idx])\n",
    "        \n",
    "        # 模型预测\n",
    "        predicted_return = self.model.predict(features)[0]\n",
    "        \n",
    "        # 交易逻辑\n",
    "        if not self.position:\n",
    "            if predicted_return > self.threshold_entry:\n",
    "                self.buy(size=self.position_size)\n",
    "        else:\n",
    "            if predicted_return < self.threshold_exit:\n",
    "                self.position.close()\n",
    "def backtest(data: pd.DataFrame, ensemble, X, y, initial_capital=100000):\n",
    "    \"\"\"执行完整回测流程\"\"\"\n",
    "    # 准备回测数据格式\n",
    "    bt_data = data.rename(columns={\n",
    "        'close': 'Close',\n",
    "        'high': 'High',\n",
    "        'low': 'Low',\n",
    "        'open': 'Open'\n",
    "    })\n",
    "    # 优化参数（可选）\n",
    "    # stats = bt.optimize(\n",
    "    #     threshold_entry=[0.01, 0.02, 0.03],\n",
    "    #     threshold_exit=[-0.01, -0.02],\n",
    "    #     maximize='Sharpe Ratio'\n",
    "    # )\n",
    "    # 初始化回测引擎\n",
    "    bt = Backtest(\n",
    "        bt_data,\n",
    "        ModelDrivenStrategy,\n",
    "        cash=100000,\n",
    "        commission=0.001,  # 考虑交易手续费\n",
    "        exclusive_orders=True\n",
    "    )\n",
    "    stats = bt.run()\n",
    "    bt.plot(filename='backtest_result.html')\n",
    "    \n",
    "    # 关键指标报告\n",
    "    print(f\"夏普比率: {stats['Sharpe Ratio','NaN']:.2f}\")\n",
    "    print(f\"最大回撤: {stats['Max. Drawdown','NaN']:.2%}\")\n",
    "    print(f\"总收益率: {stats['Return [%]','NaN']:.2f}%\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('stock.csv', index_col='date',parse_dates=True)\n",
    "    data = preprocess_data(data)\n",
    "    \n",
    "    features, target = create_features(data)\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    ensemble = train_models(features, target)\n",
    "\n",
    "     # 模拟新数据到来时的监控（示例）\n",
    "    # new_data = pd.read_csv('new_stock_data.csv') \n",
    "    # new_features, _ = create_features(preprocess_data(new_data))\n",
    "    current_drift = track_model_drift(\n",
    "        ensemble,\n",
    "        features.sample(1000),  # 假设取样本数据\n",
    "        target.sample(1000)\n",
    "    )\n",
    "    print(f\"模型性能漂移值: {current_drift:.4f}\")\n",
    "\n",
    "     # 部署集成模型\n",
    "    joblib.dump(ensemble, 'stock_predictor.pkl')\n",
    "\n",
    "    monitor = ModelMonitor('stock_predictor.pkl')\n",
    "    # 4. 执行漂移检测\n",
    "    is_drift = monitor.check_drift(\n",
    "        features.sample(1000, random_state=42),\n",
    "        target.sample(1000, random_state=42),\n",
    "        threshold=-0.15  # 根据业务需求调整阈值\n",
    "    )\n",
    "    \n",
    "    print(f\"是否需要更新模型: {is_drift}\")\n",
    "    # 显示交叉验证结果\n",
    "    # 执行回测\n",
    "    backtest_stats = backtest(data, ensemble, features, target)\n",
    "    \n",
    "    # 策略优化示例（可选）\n",
    "    optimize_params = {\n",
    "        'threshold_entry': [0.015, 0.02, 0.025],\n",
    "        'threshold_exit': [-0.005, -0.01],\n",
    "        'position_size': [0.1, 0.2]\n",
    "    }\n",
    "    optimization_results = backtest_stats.optimize(**optimize_params, maximize='Sharpe Ratio')\n",
    "    print(optimization_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
