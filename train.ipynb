{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense\n",
    "# from tensorflow.kernas.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stock_features.csv', parse_dates=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "target ='close'\n",
    "features = df.drop(columns=['date', target]).values\n",
    "X = features.copy()\n",
    "y = df[target].copy().values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'units': 64,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'd_model': 64,\n",
    "    'num_layers': 2,\n",
    "    'ff_dim': 64,\n",
    "    'num_heads': 2\n",
    "\n",
    "}\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X)\n",
    "y_train_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# 创建输入序列和标签，使用滑动窗口\n",
    "def create_sequneces(X, y, time_steps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "X_train, y_train = create_sequneces(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(\"划分数据集...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42, shuffle=False)\n",
    "X_val,X_test, y_val,y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "print(\"构建LSTM模型...\")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate= 0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()\n",
    "print(\"训练模型...\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "print(\"预测模型...\")\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predicted_prices =  scaler_y.inverse_transform(predictions)\n",
    "real_prices = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "\"\"\"模型验证和评估\"\"\"\n",
    "print(\"评估模型...\")\n",
    "mse = mean_squared_error(real_prices, predicted_prices)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(real_prices, predicted_prices)\n",
    "r2 = r2_score(real_prices, predicted_prices)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "# 绘制验证损失曲线（如果有验证集）\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.title('Model Training History')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 创建准确率曲线图（如果有准确率指标）\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Model Accuracy History')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
